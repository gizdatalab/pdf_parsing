{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is on code snippet how to use the AXA-Parsr docker container and programmatic access to it\n",
    "[This is work in progress]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations\n",
    "\n",
    "Guide: https://github.com/axa-group/Parsr/tree/master/demo/parsr-jupyter-demo\n",
    "After Parsr-client is installed we need default config to work with server API and the wrapper to handle the output.\n",
    "Check the local folder ./server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import post\n",
    "\n",
    "# this is the relative filepath of pdf to be send for processing\n",
    "file_path='../documents/testfile.pdf'\n",
    "# this is relative filepath to the configfile which is required by server to set the \n",
    "# internal module configs, forms part of POST request\n",
    "config_path='../axaserver/defaultConfig.json'\n",
    "def send_doc(url,file_path, config_path):\n",
    "    packet = {\n",
    "            'file': (file_path,\n",
    "                     open(file_path, 'rb'),\n",
    "                     'application/pdf'),\n",
    "            'config': (config_path,\n",
    "                      open(config_path, 'rb'),\n",
    "                      'application/json')\n",
    "                      }\n",
    "    r = post(url + '/api/v1/document', files=packet)\n",
    "    \n",
    "    return {\n",
    "                'file': file_path,\n",
    "                'config': config_path,\n",
    "                'status_code': r.status_code,\n",
    "                'server_response': r.text\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS EXAMPLE CODE FROM AXA REPO FOR RENDERING THE OUTPUT FROM PARSR SERVER\n",
    "\n",
    "\n",
    "# Copyright 2019 AXA Group Operations S.A.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from pygments import highlight\n",
    "from pygments.lexers import JsonLexer\n",
    "from pygments.formatters import TerminalFormatter\n",
    "\n",
    "\n",
    "class RenderJSON(object):\n",
    "\tdef __init__(self, data):\n",
    "\t\tself.render_json(data)\n",
    "\tdef render_json(self, data):\n",
    "\t\tjson_object = json.loads(json.dumps(data))\n",
    "\t\tjson_str = json.dumps(json_object, indent=4, sort_keys=True)\n",
    "\t\tprint(highlight(json_str, JsonLexer(), TerminalFormatter()))\n",
    "\n",
    "\n",
    "class RenderMarkdown(object):\n",
    "\tdef __init__(self, markdown_data):\n",
    "\t\tself.markdown_data = markdown_data\n",
    "\t\tself.uuid = str(uuid.uuid4())\n",
    "\n",
    "\tdef _ipython_display_(self):\n",
    "\t\tdisplay(Markdown(self.markdown_data))\n",
    "\n",
    "\n",
    "class RenderHTML(object):\n",
    "\tdef __init__(self, html_data=None, html_file=None):\n",
    "\t\tif not html_data and not html_file:\n",
    "\t\t\tprint(\"You need to provide either a filename or raw HTML data for something to be rendered\")\n",
    "\t\tself.html_data = html_data\n",
    "\t\tself.html_file = html_file\n",
    "\t\tself.uuid = str(uuid.uuid4())\n",
    "\n",
    "\tdef _ipython_display_(self):\n",
    "\t\tif self.html_data is not None:\n",
    "\t\t\tdisplay(HTML(self.html_data))\n",
    "\t\tif self.html_file is not None:\n",
    "\t\t\tHTML(filename=self.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from json import loads\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from ast import literal_eval\n",
    "\n",
    "# this is taken/adapted from https://github.com/axa-group/Parsr/blob/master/clients/python-client/parsr_client/parsr_client.py\n",
    "\n",
    "def get_json(request_id: str = \"\", server: str = \"\"):\n",
    "        \"\"\"Fetch the Parsr's output JSON file (result) given a particular\n",
    "        request\n",
    "\n",
    "        - request_id: The ID of the request to be queried with the server\n",
    "        - server: The server from which the JSON is to be fetched\n",
    "        \"\"\"\n",
    "\n",
    "        if server == \"\":\n",
    "            raise Exception('No server address provided')\n",
    "\n",
    "        if request_id == \"\":\n",
    "            raise Exception('No request ID provided')\n",
    "\n",
    "        r = get('{}/api/v1/json/{}'.format(server,request_id))\n",
    "        if r.text != \"\":\n",
    "            return r.json()\n",
    "        else:\n",
    "            return {'request_id': request_id, 'server_response': r.json()}\n",
    "        \n",
    "def get_text(request_id: str = \"\", server: str = \"\"):\n",
    "        \"\"\"Fetch the Parsr's output JSON file (result) given a particular\n",
    "        request\n",
    "\n",
    "        - request_id: The ID of the request to be queried with the server\n",
    "        - server: The server from which the JSON is to be fetched\n",
    "        \"\"\"\n",
    "\n",
    "        if server == \"\":\n",
    "            raise Exception('No server address provided')\n",
    "\n",
    "        if request_id == \"\":\n",
    "            raise Exception('No request ID provided')\n",
    "\n",
    "        r = get('{}/api/v1/text/{}'.format(server,request_id))\n",
    "        if r.text != \"\":\n",
    "            return r.text\n",
    "        else:\n",
    "            return {'request_id': request_id, 'server_response': r.text}\n",
    "        \n",
    "\n",
    "        \n",
    "def get_markdown(request_id: str = \"\", server: str = \"\"):\n",
    "        \"\"\"Fetch the Parsr's output JSON file (result) given a particular\n",
    "        request\n",
    "\n",
    "        - request_id: The ID of the request to be queried with the server\n",
    "        - server: The server from which the JSON is to be fetched\n",
    "        \"\"\"\n",
    "\n",
    "        if server == \"\":\n",
    "            raise Exception('No server address provided')\n",
    "\n",
    "        if request_id == \"\":\n",
    "            raise Exception('No request ID provided')\n",
    "\n",
    "        r = get('{}/api/v1/markdown/{}'.format(server,request_id))\n",
    "        if r.text != \"\":\n",
    "            return r.text\n",
    "        else:\n",
    "            return {'request_id': request_id, 'server_response': r.text}        \n",
    "\n",
    "\n",
    "def get_table(\n",
    "            request_id: str = \"\",\n",
    "            page=None,\n",
    "            table=None,\n",
    "            seperator=\";\",\n",
    "            server: str = \"\",\n",
    "            column_names: list = None):\n",
    "        \"\"\"Get a particular table from a processed document.\n",
    "\n",
    "        - request_id: The request to be queried to get a document.\n",
    "        - page: The page number on which the queried table exists.\n",
    "        - table: The table number to be fetched.\n",
    "        - seperator: The seperator to be used between table cells (default ';')\n",
    "        - server: The server address which is to be queried.\n",
    "        - column_names: The headings of the table searched (column titles)\n",
    "        \"\"\"\n",
    "        if server == \"\":\n",
    "            raise Exception('No server address provided')\n",
    "        \n",
    "        if request_id == \"\":\n",
    "            raise Exception('No request ID provided')\n",
    "        \n",
    "        if page is None and table is None:\n",
    "            r = get('{}/api/v1/csv/{}'.format(server,request_id))\n",
    "        else:\n",
    "            r = get('{}/api/v1/csv/{}/{}/{}'.format(server,\n",
    "                                                    request_id,\n",
    "                                                    page,\n",
    "                                                    table))\n",
    "\n",
    "        if r.text != \"\":\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    StringIO(\n",
    "                        r.text),\n",
    "                    sep=seperator,\n",
    "                    names=column_names)\n",
    "                df.loc[:, ~df.columns.str.match('Unnamed')]\n",
    "                df = df.where((pd.notnull(df)), \" \")\n",
    "                return df\n",
    "            except Exception:\n",
    "                return r.text\n",
    "        else:\n",
    "            return r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local-Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '../documents/testfile.pdf',\n",
       " 'config': '../axaserver/defaultConfig.json',\n",
       " 'status_code': 202,\n",
       " 'server_response': 'd6690f0638017986fe312742ffe51b'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://localhost:3001\" \n",
    "r  = send_doc(url=url,file_path=file_path,config_path=config_path)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:3001\n",
      "urllib3.connectionpool - DEBUG - http://localhost:3001 \"GET /api/v1/queue/6a47c1790b724991974571e67539ef HTTP/1.1\" 201 257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '6a47c1790b724991974571e67539ef',\n",
       " 'json': '/api/v1/json/6a47c1790b724991974571e67539ef',\n",
       " 'csv': '/api/v1/csv/6a47c1790b724991974571e67539ef',\n",
       " 'text': '/api/v1/text/6a47c1790b724991974571e67539ef',\n",
       " 'markdown': '/api/v1/markdown/6a47c1790b724991974571e67539ef'}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it can take few sec to few min to process the pdf\n",
    "r_status = get('{}/api/v1/queue/{}'.format(url,r['server_response']))\n",
    "print(r_status)\n",
    "loads(r_status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:3001\n",
      "urllib3.connectionpool - DEBUG - http://localhost:3001 \"GET /api/v1/json/6a47c1790b724991974571e67539ef HTTP/1.1\" 200 174688\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:3001\n",
      "urllib3.connectionpool - DEBUG - http://localhost:3001 \"GET /api/v1/text/6a47c1790b724991974571e67539ef HTTP/1.1\" 200 6241\n",
      "urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:3001\n",
      "urllib3.connectionpool - DEBUG - http://localhost:3001 \"GET /api/v1/markdown/6a47c1790b724991974571e67539ef HTTP/1.1\" 200 6376\n"
     ]
    }
   ],
   "source": [
    "r_json = get_json(server=url, request_id=loads(r_status.text)['id'])\n",
    "r_text = get_text(server=url, request_id=loads(r_status.text)['id'])\n",
    "r_markdown = get_markdown(server=url, request_id=loads(r_status.text)['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In accordance with decision No. 1/CP.21, paragraph 24, adopted at the Conference of the Parties to the United Nations Framework Convention on Climate Change (COP21), the Republic of Azerbaijan provides an updated version of its “Nationally Determined Contributions (NDCs)” document, as well as additional information on contributions to ensure clarity and transparency on the basis of decision No. 4/CMA.1 of the Conference of the Parties (COP24).\n",
       "\n",
       "---\n",
       "\n",
       "**The Republic of Azerbaijan** Updated document on Nationally Determined Contributions (NDC)**\n",
       "\n",
       "**2023**\n",
       "\n",
       "---\n",
       "\n",
       "**Table of Content**\n",
       "\n",
       "**Introduction**\n",
       "\n",
       "1. **Information on the process of preparation of the document “Nationally Determined Contributions”**\n",
       "2. **National circumstances**\n",
       "3. **Information on the implemented Climate Policy**\n",
       "4. **Mitigation measures of environmental impacts: 4.1 Targets for reducing greenhouse gas emissions 4.2 Sectoral policies**\n",
       "\n",
       "---\n",
       "\n",
       "**Introduction**\n",
       "\n",
       "As agreed at the Conference of the Parties in Paris (COP21), all party states, regardless of their level of development and political objectives, shall mobilise more intensively to take urgent actions for achieving the goals of the Paris Agreement.\n",
       "\n",
       "According to the 6th Assessment Report of the Intergovernmental Panel on Climate Change (IPCC), global temperatures will continue to rise until at least the middle of this century under all scenarios considered for emissions. Moreover, global warming will exceed 1.5°C or 2°C in the 21st century unless drastic reductions in emissions of carbon dioxide (CO2) and other greenhouse gases (GHGs) are achieved in the coming decades.\n",
       "\n",
       "The Republic of Azerbaijan actively participates in the implementation of the United Nations Framework Convention on Climate Change (UNFCCC), the Kyoto Protocol and the Paris Agreement.\n",
       "\n",
       "In accordance with Article 4 of the Paris Agreement, the Republic of Azerbaijan has introduced its Nationally Determined Contributions (NDC) to the UNFCCC Secretariat in October 2015 and as a contribution to initiatives for preventing global climate change (mitigation initiatives) compared to 1990 (base year) aims to reduce greenhouse gas emissions by 35% by 2030.\n",
       "\n",
       "Since then, the evaluation of the policies pursued by the government and the assessment of the measures taken has created an opportunity to propose a higher target to the government of Azerbaijan. Taking into account the new realities after the liberation of about 20 percent of the country's territories from a 30-year occupation and strategic socio-economic development programmes, national circumstances, especially the plans for diversification of the economy over the next decade, the proposed GHG emission reduction target by 2030 in Azerbaijan's Nationally Determined Contribution document is quite ambitious.\n",
       "\n",
       "Azerbaijan plans to take part in reducing the environmental impact on the basis of its NDC document, primarily through its domestic capacities and has, nevertheless, taken important steps in international cooperation in accordance with Article 6 of the Paris Agreement.\n",
       "\n",
       "The new version of **Azerbaijan's Nationally Determined Contributions by 2050** includes the following elements:\n",
       "\n",
       "**Azerbaijan's Nationally Determined Contributions by 2050** were renewed in 2023.\n",
       "\n",
       "The Republic of Azerbaijan, subject to its sustainable socio-economic development, will seek to reduce greenhouse gas emissions by 40% compared to 1990 (base year) level by 2050 if international support is provided through financing, technology transfer and capacity building.\n",
       "\n",
       "| As per the instructions outlined in the decision 4/CMA. |<|  \n",
       "|---|---|  \n",
       "| **Quantitative data as of the reference date (including base year, if applicable):** |<|  \n",
       "| Reference (base) year | 1990 |  \n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "| Quantitative data as of reference date the | In the 4 th National Communication of Azerbaijan, the total volume of greenhouse gas emissions for the reporting year (taking into account the absorption volume in the land use, land-use change and forestry (LULUCF) sector) is assumed to be 79 Mt of CO2 equivalent \\*1 |  \n",
       "|---|---|  \n",
       "| Objective regarding numerical reference | Reduction of greenhouse gas emissions by up to 40% compared to 1990 level, taking into account the maximum absorption capacity of forests and other ecosystems. |  \n",
       "| Conditions for changing reference indicators | Total greenhouse gas emissions into the atmosphere can be and through methodological improvements. Updates will be included in the next Biennial Update Report or Biennial and National Communication. Transparency Report updated  recalculated |  \n",
       "| **Deadlines and/or terms for execution:** |<|  \n",
       "| The deadlines and/or terms for execution, as well as the start and end date, in accordance with any relevant decision made at the Conference of the Parties of the Paris Agreement | From 1 January 2023 to 31 December 2050. |  \n",
       "| Consideration of paragraphs 31 (c) and (d) of decision 1/CP.21 by the country | included inventory. In its 4th National Communication, Azerbaijan recorded updated information on sources included in the greenhouse gas  Information on greenhouse gas emissions into the atmosphere from sources that have not been accounted for due to lack of data will be  the reports after restructuring of the Monitoring, Reporting and Verification (MRV) system in accordance with the requirements of the improved transparency format specified in Article 13 of the Paris Agreement. If air emissions from these sources are significant, i.e., if they are considered a key emission sector, Azerbaijan will provide relevant clarifying information on these emissions the UNFCCC Secretariat. in the next reports to in |  \n",
       "| **Scale and scope:** |<|  \n",
       "| General description of the target | Target covering all sectors |  \n",
       "\n",
       "\n",
       "1 *It should be noted that during the GHG inventory for 1990 (base year), there was some missing data to calculate emissions/absorbances for all categories mentioned in the relevant methodological guidelines prepared by the IPCC in 2006. In this regard, when inventories are conducted in subsequent years based on more complete data for the base year, the GHG emission figure for that year may be subject to change in the assessment. Moreover, due to the lack of data for the occupied territories of Azerbaijan for about 30 years, it is foreseen to recalculate emissions/absorbances for this period.*\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, HTML\n",
    "display(Markdown(r_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:3001\n",
      "urllib3.connectionpool - DEBUG - http://localhost:3001 \"GET /api/v1/csv/6a47c1790b724991974571e67539ef HTTP/1.1\" 200 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 tables on page 4\n",
      "There are 1 tables on page 5\n"
     ]
    }
   ],
   "source": [
    "# we can get first list of tables and then use same fucntion to get the tables one by one\n",
    "tables =  get_table(server=url,request_id=loads(r_status.text)['id'])\n",
    "\n",
    "for table in literal_eval(tables.columns[0]):\n",
    "    print(\"There are {} tables on page {}\".format(table.rsplit('/')[-1],table.rsplit('/')[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): localhost:3001\n",
      "urllib3.connectionpool - DEBUG - http://localhost:3001 \"GET /api/v1/csv/6a47c1790b724991974571e67539ef/5/1 HTTP/1.1\" 200 1925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantitative data as of reference date the</th>\n",
       "      <th>In the 4 th National Communication of Azerbaijan, the total volume of greenhouse gas emissions for the reporting year (taking into account the absorption volume in the land use, land-use change and forestry (LULUCF) sector) is assumed to be 79 Mt of CO2 equivalent *1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Objective regarding numerical reference</td>\n",
       "      <td>Reduction of greenhouse gas emissions by up to 40% compared to 1990 level, taking into account the maximum absorption capacity of forests and other ecosystems.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conditions for changing reference indicators</td>\n",
       "      <td>Total greenhouse gas emissions into the atmosphere can be and through methodological improvements. Updates will be included in the next Biennial Update Report or Biennial and National Communication. Transparency Report updated recalculated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deadlines and/or terms for execution:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The deadlines and/or terms for execution, as well as the start and end date, in accordance with any relevant decision made at the Conference of the Parties of the Paris Agreement</td>\n",
       "      <td>From 1 January 2023 to 31 December 2050.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consideration of paragraphs 31 (c) and (d) of decision 1/CP.21 by the country</td>\n",
       "      <td>included inventory. In its 4th National Communication, Azerbaijan recorded updated information on sources included in the greenhouse gas Information on greenhouse gas emissions into the atmosphere from sources that have not been accounted for due to lack of data will be the reports after restructuring of the Monitoring, Reporting and Verification (MRV) system in accordance with the requirements of the improved transparency format specified in Article 13 of the Paris Agreement. If air emissions from these sources are significant, i.e., if they are considered a key emission sector, Azerbaijan will provide relevant clarifying information on these emissions the UNFCCC Secretariat. in the next reports to in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scale and scope:</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>General description of the target</td>\n",
       "      <td>Target covering all sectors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "# pass page number and table_number\n",
    "df = get_table(server=url,request_id=loads(r_status.text)['id'], page=5, table=1)\n",
    "display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filetest.md', 'w') as file:\n",
    "    file.write(r_markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace (public server)\n",
    "\n",
    "Follow the instructions: https://huggingface.co/docs/hub/en/spaces-sdks-docker\n",
    "\n",
    "*Dockerfile*\n",
    "\n",
    "`FROM axarev/parsr\n",
    "\n",
    "EXPOSE 3001:3001`\n",
    "\n",
    "*Readme.md*\n",
    "sdk: docker\n",
    "app_port: 3001\n",
    "\n",
    "For the API end points: Get the 'Direct URL' from the 'Embed this space' from options next to 'Settings' on space Ui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): giz-axaparsr-server.hf.space:443\n",
      "urllib3.connectionpool - DEBUG - https://giz-axaparsr-server.hf.space:443 \"POST /api/v1/document HTTP/1.1\" 202 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file': './documents/testfile.pdf',\n",
       " 'config': './server/defaultConfig.json',\n",
       " 'status_code': 202,\n",
       " 'server_response': '10df52d730e892b93897c683778de7'}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://giz-axaparsr-server.hf.space\"\n",
    "r  = send_doc(url=url,file_path=file_path,config_path=config_path)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): giz-axaparsr-server.hf.space:443\n",
      "urllib3.connectionpool - DEBUG - https://giz-axaparsr-server.hf.space:443 \"GET /api/v1/queue/10df52d730e892b93897c683778de7 HTTP/1.1\" 201 257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '10df52d730e892b93897c683778de7',\n",
       " 'json': '/api/v1/json/10df52d730e892b93897c683778de7',\n",
       " 'csv': '/api/v1/csv/10df52d730e892b93897c683778de7',\n",
       " 'text': '/api/v1/text/10df52d730e892b93897c683778de7',\n",
       " 'markdown': '/api/v1/markdown/10df52d730e892b93897c683778de7'}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it can take few sec to few min to process the pdf\n",
    "r_status = get('{}/api/v1/queue/{}'.format(url,r['server_response']))\n",
    "print(r_status)\n",
    "loads(r_status.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Container Instance (public server)\n",
    "\n",
    "Add the TCP 3001 port when creating container. \n",
    "Once container is up and running use FQDN for API endpoints\n",
    "\n",
    "API end points will be : FQDN:3001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): axaparsr.dggxf4fce9athrhp.westeurope.azurecontainer.io:3001\n",
      "urllib3.connectionpool - DEBUG - http://axaparsr.dggxf4fce9athrhp.westeurope.azurecontainer.io:3001 \"POST /api/v1/document HTTP/1.1\" 202 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file': './documents/testfile.pdf',\n",
       " 'config': './server/defaultConfig.json',\n",
       " 'status_code': 202,\n",
       " 'server_response': '81cdc32d7da23ef2a2488b68665b9a'}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://axaparsr.dggxf4fce9athrhp.westeurope.azurecontainer.io:3001\"\n",
    "r  = send_doc(url=url,file_path=file_path,config_path=config_path)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from haystack.nodes import ParsrConverter\n",
    "# converter = ParsrConverter()\n",
    "# import os\n",
    "\n",
    "# def process(file):\n",
    "#     # print(file)\n",
    "#     docs = converter.convert(file)\n",
    "#     return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import glob\n",
    "# path_to_data = './documents/MWTS/'\n",
    "# mwts_placeholder = []\n",
    "# files = glob.glob(path_to_data+\"*\")\n",
    "# for file in files:\n",
    "#     try:\n",
    "#         docs = process(file)\n",
    "#         mwts_placeholder.append({'filename':os.path.basename(file),'haystack_doc':docs})\n",
    "#     except:\n",
    "#         print(f\"error in processing {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from parsr_client import ParsrClient as client\n",
    "# parsr = client('localhost:3001')\n",
    "\n",
    "# job = parsr.send_document(\n",
    "#     file_path='./documents/testfile.pdf',\n",
    "#     config_path='./server/defaultConfig.json',\n",
    "#     document_name='Sampletest',\n",
    "#     wait_till_finished=False,\n",
    "#     save_request_id=True,\n",
    "# )\n",
    "\n",
    "# RenderJSON(job)\n",
    "# parsr.get_status(\"a135af11bbf348ef193144e756b4d7\")\n",
    "# r = get('http://{}/api/v1/markdown/{}'.format(parsr.server, \"a135af11bbf348ef193144e756b4d7\"))\n",
    "# url = \"https://giz-parsrtest.hf.space:3001\"\n",
    "# from parsr_client import ParsrClient as client\n",
    "# parsr = client(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dscbasic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a29ce63817df02469b2e31ad6d3de26d7effa8635b4e7c0571b49c965a7a8b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
